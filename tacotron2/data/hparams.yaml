################################
# Experiment Parameters        #
################################
device: "cuda:0"

epochs: 100
iters_per_checkpoint: 2500

output_dir: "/home/user/Documents/CONDA/TTS-dev/dataset/natasha_dataset/result"
log_dir: logs

checkpoint: 
warm_start: true

seed: 1234
dynamic_loss_scaling: True
fp16_run: true

dist_backend: "nccl"
dist_url: "tcp://localhost:54321"

cudnn_enabled: True
cudnn_benchmark: False

ignore_layers: ['embedding.weight']
ignore_mismatched_layers: True  # automatically ignore checkpoint layers with another shape

################################
# Data Parameters             #
################################
load_mel_from_disk: False
audios_path: "/home/user/Documents/CONDA/TTS-dev/dataset/natasha_dataset/"
alignments_path:
  original:
  stressed:
training_files: "/home/user/Documents/CONDA/TTS-dev/dataset/natasha_dataset/train/marks.txt"
validation_files: "/home/user/Documents/CONDA/TTS-dev/dataset/natasha_dataset/test/marks.txt"

charset: "ru" # possible entries: en, ru, ru_trans
text_handler_cfg: # data/text_handler_cfg.yaml

# mask_stress: Union[float, bool]. If float, the number must be in {0, 1} - the probability of masking stressed
# words into learning process (passing them unstressed)
mask_stress: 0.15
# mask_phonemes: Union[float, bool]. If float, the number must be in {0, 1} - the probability of masking phoneme
# representation of words into learning process (passing them in grapheme representation)
mask_phonemes: True
word_level_prob: True

shuffle: true
optimize: false
len_diff: 10

################################
# Audio Parameters             #
################################
max_wav_value: 32768.0
sampling_rate: 22050
filter_length: 1024
hop_length: 256
win_length: 1024
n_mel_channels: 80
mel_fmin: 0.0
mel_fmax: 8000.0

add_silence: True
trim_silence: False
trim_top_db: 45 # empirically

################################
# Model Parameters             #
################################
symbols_embedding_dim: 512
activation: "relu"

# Encoder parameters
encoder_kernel_size: 5
encoder_n_convolutions: 3
encoder_embedding_dim: 512

# Decoder parameters
n_frames_per_step: 1  # currently only 1 is supported
decoder_rnn_dim: 1024
prenet_dim: 256
max_decoder_steps: 1000
gate_threshold: 0.5
p_attention_dropout: 0.1
p_decoder_dropout: 0.1

# Attention parameters
attention_rnn_dim: 1024
attention_dim: 128

# Location Layer parameters
attention_location_n_filters: 32
attention_location_kernel_size: 31

# Mel-post processing network parameters
postnet_embedding_dim: 512
postnet_kernel_size: 5
postnet_n_convolutions: 5

# GST reference encoder
use_gst: False

reference_encoder_filters: [32, 32, 64, 64, 128, 128]
reference_encoder_kernel: [3, 3]
reference_encoder_strides: [2, 2]
reference_encoder_pad: [1, 1]
reference_encoder_activation: "relu"

# GST style token layer
stl_token_num: 10
stl_num_heads: 8

################################
# Optimization Hyperparameters #
################################

# loss functions parameters
guided_attention_type: "diagonal" # possible entries: 'none', 'diagonal', 'prealigned'
attention_weight: 1.0
diagonal_factor: 0.15 #
include_padding: False # how to calculate loss for attention: considering padding values or not

# mel_loss_type: type of the loss function used to penalize wrong mel predictions
# possible entries: 'MSE', 'L1'
mel_loss_type: "MSE"
gate_positive_weight: 10.0

# optimizers from https://github.com/jettify/pytorch-optimizer
optimizer: "adam" # possible entries: 'sgd', 'adam', 'radam', 'diffgrad', 'novograd', 'yogi', 'adabound'
learning_rate: 1e-3
weight_decay: 1e-6
optim_options:

# Lookahead wrapper around the optimizer, stabilizes exploration of the loss surface and improves convergence
# examples: Ranger = RAdam + LookAhead
with_lookahead: False

lr_scheduler: "multi_step" # possible entries: 'none', 'multi_step', 'exp', 'plateau', 'cyclic'
lr_scheduler_options:
#  max_lr: !!float 1e-3
#  base_lr: !!float 1e-5
#  mode: "exp_range"
#  gamma: 0.9
#  cycle_momentum: false
  gamma: 0.1
  milestones: [70, 90]
restore_scheduler_state: False

grad_clip_thresh: 1.0
batch_size: 16
mask_padding: True  # set model's padded outputs to padded values

# other parameters
initscheme: "xavier_uniform"

##################################
# MMI options                    #
##################################
use_mmi: False
use_gaf: True
max_gaf: 0.3

##################################
# Teacher forcing control        #
##################################
# tf_replacement: type of the mechanism that limits usage of the teacher forcing;
# possible entries:
#   'none' - teacher forcing is always used
#   'global_mean' - some frames will be replaced by dataset global mean value
#   'decoder_output' - some frames will be replaced by decoder outputs from previous step
tf_replacement: "none"

# p_tf_train, p_tf_val: probability with which frames will be treated in conventional teacher forcing mode
# during training and validation respectively
p_tf_train: 1.0
p_tf_val: 1.0

global_mean_npy:
